"""
Kokoro-82M TTS å¼•æ“å°è£… (v1.0 ONNX é«˜æ€§èƒ½ç‰ˆ)
åŸºäºå®˜æ–¹ç¤ºä¾‹: https://github.com/thewh1teagle/kokoro-onnx/blob/main/examples/save.py
"""
import os
import time
import numpy as np
import threading
from typing import Optional, Generator
from loguru import logger

class KokoroEngine:
    """Kokoro-82M TTS å¼•æ“ï¼ŒåŸºäº kokoro-onnx æ¨ç†åº“"""
    
    def __init__(self, model_path: str, voices_path: str):
        """
        Args:
            model_path: kokoro-v1.0.onnx çš„è·¯å¾„
            voices_path: voices-v1.0.bin çš„è·¯å¾„
        """
        self.model_path = model_path
        self.voices_path = voices_path
        self._kokoro = None
        self._loaded = False
        self._lock = threading.RLock() # ğŸ”’ å¯é‡å…¥é”ï¼Œé˜²æ­¢é¢„çƒ­æ—¶æ­»é”
        self.sample_rate = 24000

    def _load_model(self):
        with self._lock: # ç¡®ä¿åªæœ‰ä¸€ä¸ªçº¿ç¨‹åœ¨è·‘åˆå§‹åŒ–
            if not self._loaded:
                try:
                    # ğŸ“¢ é‡è¦ï¼šespeakng_loader å¿…é¡»åœ¨ phonemizer/kokoro_onnx ä¹‹å‰å¯¼å…¥
                    try:
                        import espeakng_loader
                        logger.info("âœ… espeakng_loader initialized")
                    except ImportError:
                        logger.warning("âš ï¸ espeakng_loader not found")
                    
                    from kokoro_onnx import Kokoro
                    start_time = time.time()
                    
                    if not os.path.exists(self.model_path):
                        raise FileNotFoundError(f"Model file not found: {self.model_path}")

                    # ğŸ“¢ å¼ºåˆ¶å¼€å¯ GPU è°ƒåº¦
                    import onnxruntime as ort
                    available_providers = ort.get_available_providers()
                    target_providers = ['CUDAExecutionProvider', 'CPUExecutionProvider']
                    
                    original_session = ort.InferenceSession
                    def forced_gpu_session(path_or_bytes, sess_options=None, providers=None, **kwargs):
                        actual_providers = [p for p in target_providers if p in available_providers]
                        return original_session(path_or_bytes, sess_options=sess_options, providers=actual_providers, **kwargs)
                    
                    import json
                    original_load = np.load
                    original_json_load = json.load
                    
                    # æ³¨å…¥è¡¥ä¸ (ä¿®å¤äº† allow_pickle é‡å¤ä¼ å‚çš„é—®é¢˜)
                    def safe_np_load(*args, **kwargs):
                        kwargs['allow_pickle'] = True
                        return original_load(*args, **kwargs)

                    ort.InferenceSession = forced_gpu_session
                    np.load = safe_np_load
                    json.load = lambda f, **k: original_json_load(f, **k)
                    
                    try:
                        logger.info(f"ğŸš€ Initializing Kokoro with GPU Providers: {target_providers}")
                        self._kokoro = Kokoro(self.model_path, self.voices_path)
                    finally:
                        ort.InferenceSession = original_session
                        np.load = original_load
                        json.load = original_json_load

                    self._loaded = True
                    logger.info(f"âœ… Kokoro-ONNX v1.0 ready in {time.time() - start_time:.4f}s!")
                    
                    # ğŸ“¢ é¢„çƒ­
                    try:
                        logger.info("ğŸ”¥ Warming up GPU kernels...")
                        self.synthesize("warmup", voice="af_sarah")
                    except Exception as e:
                        logger.warning(f"âš ï¸ Warmup failed: {e}")

                except Exception as e:
                    logger.error(f"âŒ Failed to load Kokoro-ONNX: {e}")
                    raise
        return self._kokoro

    def synthesize(self, text: str, voice: str = "af_sarah", lang: str = "en-us", 
                   speed: float = 1.0, output_path: Optional[str] = None) -> np.ndarray:
        """
        åˆæˆè¯­éŸ³ (å¸¦æ–‡æœ¬æ¸…æ´—å’Œå¹¶å‘é”)
        """
        kokoro = self._load_model()
        
        # 1. æ–‡æœ¬æ·±åº¦æ¸…æ´— (è§£å†³æåº¦å¤æ‚çš„å­—ç¬¦å¯¼è‡´çš„å´©æºƒ)
        import re
        
        # A. æ›¿æ¢å·²çŸ¥ä¼šå¼•å‘è¡Œå·å˜åŒ–çš„ç‰¹æ®Šå­—ç¬¦
        text = text.replace('â€”', '-') 
        text = text.replace('Â°', ' degrees ')
        
        # B. ç§»é™¤ Emoji è¡¨æƒ… (Unicode èŒƒå›´è¿‡æ»¤)
        text = re.sub(r'[\U00010000-\U0010ffff]', '', text)
        
        # C. è¿‡æ»¤éæ³•å­—ç¬¦ï¼šä»…ä¿ç•™å¯æ‰“å°å­—ç¬¦ï¼Œå¹¶ç§»é™¤ Box Drawing ç­‰ç‰¹æ®Šç¬¦å·å—
        text = "".join(ch for ch in text if ch.isprintable())
        
        # D. å¼ºåˆ¶å•è¡ŒåŒ–ï¼Œå¤„ç†ç©ºç™½ç¬¦
        text = re.sub(r'[\r\n\t]+', ' ', text)
        text = re.sub(r'\s+', ' ', text).strip()
        
        if not text:
            logger.warning("âš ï¸ æ–‡æœ¬æ¸…æ´—åä¸ºç©ºï¼Œè·³è¿‡åˆæˆ")
            return np.array([], dtype=np.float32)

        start_time = time.time()
        
        # 2. çº¿ç¨‹å®‰å…¨æ¨ç† (phonemizer/espeak åœ¨å¤šçº¿ç¨‹ä¸‹æä¸ç¨³å®š)
        with self._lock:
            try:
                logger.info(f"ğŸ¤ [Kokoro-v1.0] Synthesizing: {text[:50]}...")
                # ä½¿ç”¨å®˜æ–¹ create() æ–¹æ³•
                samples, sample_rate = kokoro.create(
                    text, voice=voice, speed=speed, lang=lang
                )
                self.sample_rate = sample_rate
                
                elapsed = time.time() - start_time
                logger.info(f"â±ï¸ [Kokoro-v1.0] Synthesis completed in {elapsed:.4f}s")
                
                if output_path:
                    import soundfile as sf
                    os.makedirs(os.path.dirname(output_path) or ".", exist_ok=True)
                    sf.write(output_path, samples, sample_rate)
                    logger.info(f"ğŸ’¾ Saved audio to {output_path}")
                    
                return samples
                
            except Exception as e:
                logger.error(f"âŒ Kokoro-v1.0 synthesis failed: {e}")
                raise

    def synthesize_stream(self, text: str, voice: str = "af_sarah", lang: str = "en-us",
                          speed: float = 1.0) -> Generator[bytes, None, None]:
        """
        æµå¼åˆæˆ (å°†ç”Ÿæˆçš„éŸ³é¢‘å°è£…ä¸ºæ ‡å‡† WAV å­—èŠ‚æµ)
        """
        import io
        import soundfile as sf
        
        samples = self.synthesize(text, voice, lang, speed)
        
        # å°†ç»“æœå†™å…¥å†…å­˜ä¸­çš„ WAV æ ¼å¼
        buffer = io.BytesIO()
        sf.write(buffer, samples, self.sample_rate, format='WAV')
        buffer.seek(0)
        
        # åå‡ºå­—èŠ‚
        yield buffer.read()

