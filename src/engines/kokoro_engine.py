"""
Kokoro-82M TTS å¼•æ“å°è£… (v1.0 ONNX é«˜æ€§èƒ½ç‰ˆ)
åŸºäºå®˜æ–¹ç¤ºä¾‹: https://github.com/thewh1teagle/kokoro-onnx/blob/main/examples/save.py
"""
import os
import time
import numpy as np
import threading
from typing import Optional, Generator
from loguru import logger

class KokoroEngine:
    """Kokoro-82M TTS å¼•æ“ï¼ŒåŸºäº kokoro-onnx æ¨ç†åº“"""
    
    def __init__(self, model_path: str, voices_path: str):
        """
        Args:
            model_path: kokoro-v1.0.onnx çš„è·¯å¾„
            voices_path: voices-v1.0.bin çš„è·¯å¾„
        """
        self.model_path = model_path
        self.voices_path = voices_path
        self._kokoro = None
        self._loaded = False
        self._lock = threading.RLock() # ğŸ”’ å¯é‡å…¥é”ï¼Œé˜²æ­¢é¢„çƒ­æ—¶æ­»é”
        self.sample_rate = 24000

    def _load_model(self):
        with self._lock:  # ç¡®ä¿åªæœ‰ä¸€ä¸ªçº¿ç¨‹åœ¨è·‘åˆå§‹åŒ–
            if not self._loaded:
                try:
                    # ğŸ“¢ æ˜¾å¼è®¾ç½® espeakng è·¯å¾„
                    import espeakng_loader
                    from phonemizer.backend.espeak.wrapper import EspeakWrapper
                    logger.info(f"ğŸ“ Espeak Library: {espeakng_loader.get_library_path()}")
                    EspeakWrapper.set_library(espeakng_loader.get_library_path())
                    EspeakWrapper.set_data_path(espeakng_loader.get_data_path())
                    
                    from kokoro_onnx import Kokoro
                    import onnxruntime as ort
                    start_time = time.time()
                    
                    # ğŸš€ æè‡´æ€§èƒ½ Session é…ç½®
                    sess_options = ort.SessionOptions()
                    sess_options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL
                    sess_options.add_session_config_entry("session.use_device_allocator_for_initializers", "1")
                    
                    available_providers = ort.get_available_providers()
                    target_providers = ['CUDAExecutionProvider', 'CPUExecutionProvider']
                    actual_providers = [p for p in target_providers if p in available_providers]

                    try:
                        # æˆ‘ä»¬æ‰‹åŠ¨åˆ›å»º Session ä»¥ä¾¿æ³¨å…¥é…ç½®
                        logger.info(f"ğŸš€ Initializing Kokoro Session with: {actual_providers}")
                        self._kokoro = Kokoro(self.model_path, self.voices_path)
                        
                        # ğŸ’¡ å¼ºåˆ¶åˆ·æ–°ä¸ºä¼˜åŒ–åçš„ Session
                        self._kokoro.sess = ort.InferenceSession(
                            self.model_path, 
                            sess_options=sess_options, 
                            providers=actual_providers
                        )
                    except Exception as e:
                        logger.error(f"âŒ Failed to init Kokoro session: {e}")
                        raise

                    self._loaded = True
                    logger.info(f"âœ… Kokoro-ONNX v1.0 ready in {time.time() - start_time:.4f}s!")
                    
                    # ğŸ“¢ é¢„çƒ­
                    try:
                        logger.info("ğŸ”¥ Warming up GPU with complex sentence...")
                        self.synthesize("Optimization confirmed. The system is operating at maximum efficiency on the Tesla V-100 GPU.")
                    except Exception as e:
                        logger.warning(f"âš ï¸ Warmup failed: {e}")

                except Exception as e:
                    logger.error(f"âŒ Failed to load Kokoro-ONNX: {e}")
                    raise
        return self._kokoro

    def synthesize(self, text: str, voice: str = "af_sarah", lang: str = "en-us", 
                   speed: float = 1.0, output_path: Optional[str] = None) -> np.ndarray:
        """
        åˆæˆè¯­éŸ³ (å¸¦ç²¾ç»†è®¡æ—¶å’Œä¼˜åŒ–è·¯å¾„)
        """
        kokoro = self._load_model()
        
        # æ–‡æœ¬æ·±åº¦æ¸…æ´—
        import re
        text = text.replace('â€”', '-').replace('Â°', ' degrees ')
        text = re.sub(r'[\U00010000-\U0010ffff]', '', text)
        text = "".join(ch for ch in text if ch.isprintable())
        text = re.sub(r'[\r\n\t]+', ' ', text)
        text = re.sub(r'\s+', ' ', text).strip()
        
        if not text:
            return np.array([], dtype=np.float32)

        start_time = time.time()
        
        try:
            # 1. éŸ³ç´ è½¬æ¢é˜¶æ®µ (CPU)
            pho_start = time.time()
            with self._lock:
                voice_style = voice
                if isinstance(voice, str):
                    voice_style = kokoro.get_voice_style(voice)
                # æå–éŸ³ç´ 
                phonemes = kokoro.tokenizer.phonemize(text, lang=lang)
            pho_duration = time.time() - pho_start

            # 2. æ¨ç†é˜¶æ®µ (GPU) - å·²ç”± RLock ä¿è¯å•å¼•æ“å®‰å…¨
            infer_start = time.time()
            with self._lock:
                # ä½¿ç”¨ is_phonemes=True è·³è¿‡å†…éƒ¨è½¬æ¢ï¼Œtrim=False ç»´æŒæé€Ÿ
                samples, sample_rate = kokoro.create(
                    phonemes, voice=voice_style, speed=speed, lang=lang, 
                    is_phonemes=True, trim=False
                )
            infer_duration = time.time() - infer_start
            
            self.sample_rate = sample_rate
            total_duration = time.time() - start_time
            logger.info(f"â±ï¸ [Kokoro] Total: {total_duration:.3f}s | Phonemes: {pho_duration:.3f}s | Infer: {infer_duration:.3f}s")
            
            if output_path:
                import soundfile as sf
                os.makedirs(os.path.dirname(output_path) or ".", exist_ok=True)
                sf.write(output_path, samples, sample_rate)
                
            return samples
            
        except Exception as e:
            logger.error(f"âŒ Kokoro synthesis failed: {e}")
            raise

    def synthesize_stream(self, text: str, voice: str = "af_sarah", lang: str = "en-us",
                          speed: float = 1.0) -> Generator[bytes, None, None]:
        """
        æµå¼åˆæˆ (å°†ç”Ÿæˆçš„éŸ³é¢‘å°è£…ä¸ºæ ‡å‡† WAV å­—èŠ‚æµ)
        """
        import io
        import soundfile as sf
        
        samples = self.synthesize(text, voice, lang, speed)
        
        # å°†ç»“æœå†™å…¥å†…å­˜ä¸­çš„ WAV æ ¼å¼
        buffer = io.BytesIO()
        sf.write(buffer, samples, self.sample_rate, format='WAV')
        buffer.seek(0)
        
        # åå‡ºå­—èŠ‚
        yield buffer.read()

