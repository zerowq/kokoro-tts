"""
Kokoro TTS FastAPI ä¸»ç¨‹åº
"""
import uvicorn
import uuid
import os
from pathlib import Path
ROOT_DIR = Path(__file__).parent.parent.absolute()

from fastapi import FastAPI, HTTPException
from fastapi.responses import StreamingResponse, FileResponse
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel
from typing import Optional
from loguru import logger

from src.config import config
from src.core.service import get_service

app = FastAPI(
    title="Kokoro TTS API",
    description="Lightweight Kokoro-82M TTS Service",
    version="0.1.0"
)

class TTSRequest(BaseModel):
    text: str
    voice: Optional[str] = "af_sarah"
    lang: Optional[str] = "en-us"
    speed: Optional[float] = 1.0

class TTSResponse(BaseModel):
    success: bool
    audio_url: str

# æŒ‚è½½é™æ€æ–‡ä»¶
static_path = ROOT_DIR / "static"
output_path = config.OUTPUT_DIR

if static_path.exists():
    app.mount("/static", StaticFiles(directory=str(static_path)), name="static")
if output_path.exists():
    app.mount("/output", StaticFiles(directory=str(output_path)), name="output")

@app.get("/")
async def root():
    index_file = static_path / "index.html"
    if index_file.exists():
        return FileResponse(index_file)
    return {"service": "Kokoro TTS", "status": "running"}


@app.get("/api/health")
async def health():
    service = get_service()
    return service.get_health()

@app.post("/api/tts", response_model=TTSResponse)
async def synthesize(request: TTSRequest):
    """åˆæˆè¯­éŸ³å¹¶ä¿å­˜ä¸º WAV æ–‡ä»¶"""
    try:
        filename = f"{uuid.uuid4()}.wav"
        output_path = config.OUTPUT_DIR / filename
        
        service = get_service()
        service.synthesize(
            text=request.text,
            voice=request.voice,
            lang=request.lang,
            speed=request.speed,
            output_path=str(output_path)
        )
        
        return TTSResponse(
            success=True,
            audio_url=f"/output/{filename}"
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/tts/stream")
@app.post("/api/tts/stream")
async def synthesize_stream(
    text: Optional[str] = None, 
    voice: Optional[str] = "af_sarah", 
    lang: Optional[str] = "en-us", 
    speed: Optional[float] = 1.0,
    request: Optional[TTSRequest] = None
):
    """æµå¼åˆæˆè¯­éŸ³ API (å…¼å®¹å¤šç§ä¼ å‚æ–¹å¼)"""
    try:
        # 1. ä¼˜å…ˆçº§: POST Body > GET Query
        if request:
            text = request.text
            voice = request.voice
            lang = request.lang
            speed = request.speed
        
        if not text:
            raise HTTPException(status_code=400, detail="Text is required")

        service = get_service()
        gen = service.synthesize_stream(
            text=text,
            voice=voice,
            lang=lang,
            speed=speed
        )
        
        # ä¸ºäº†è®©æµè§ˆå™¨ç›´æ¥æ’­æ”¾ï¼Œè¿™é‡Œå¿…é¡»è¿”å›å®Œæ•´çš„äºŒè¿›åˆ¶æµ (åŒ…å« WAV å¤´çš„æ¨¡æ‹Ÿ)
        # æ³¨æ„ï¼šç”±äº Kokoro ç›®å‰æ˜¯æ•´æ®µç”Ÿæˆï¼Œæˆ‘ä»¬ç›´æ¥å°†ç”Ÿæˆå¥½çš„ç»“æœæµå¼åå‡º
        return StreamingResponse(gen, media_type="audio/wav")
    except Exception as e:
        logger.error(f"âŒ API Error: {e}")
        raise HTTPException(status_code=500, detail=str(e))



if __name__ == "__main__":
    print("\n" + "=" * 60)
    print("ğŸ¤ Kokoro TTS Service Starting")
    print("=" * 60)
    
    # ğŸ” ç³»ç»Ÿç¯å¢ƒè‡ªæ£€ (ä»…æ£€æŸ¥ONNX Runtimeï¼Œé¿å…torch CUDAåˆå§‹åŒ–é—®é¢˜)
    try:
        import onnxruntime as ort
        import os
        
        print(f"ğŸ” [DEBUG] ONNX Runtime version: {ort.__version__}")
        print(f"ğŸ” [DEBUG] LD_LIBRARY_PATH: {os.environ.get('LD_LIBRARY_PATH', 'Not set')}")
        print(f"ğŸ” [DEBUG] CUDA_HOME: {os.environ.get('CUDA_HOME', 'Not set')}")
        
        providers = ort.get_available_providers()
        print(f"ğŸ“Š [ONNX] Available Providers: {providers}")
        
        # å°è¯•è·å–CUDAè®¾å¤‡ä¿¡æ¯
        try:
            session_options = ort.SessionOptions()
            providers_with_options = [
                ('CUDAExecutionProvider', {
                    'device_id': 0,
                    'arena_extend_strategy': 'kNextPowerOfTwo',
                    'gpu_mem_limit': 2 * 1024 * 1024 * 1024,
                    'cudnn_conv_algo_search': 'EXHAUSTIVE',
                    'do_copy_in_default_stream': True,
                })
            ]
            print(f"ğŸ” [DEBUG] Trying to create CUDA session...")
        except Exception as e:
            print(f"âš ï¸ [DEBUG] CUDA session creation failed: {e}")
        
        if 'CUDAExecutionProvider' in providers or 'TensorrtExecutionProvider' in providers:
            print(f"ğŸš€ [DEVICE] GPU acceleration enabled via ONNX Runtime")
        else:
            print("ğŸ’¡ [DEVICE] Running on CPU")
            print("âš ï¸ [HINT] If GPU should be available, check:")
            print("   - CUDA libraries are in LD_LIBRARY_PATH")
            print("   - onnxruntime-gpu is built with CUDA support")
            print("   - Docker container has GPU access (--gpus flag)")
    except Exception as e:
        print(f"âš ï¸ [ONNX] Could not get providers: {e}")

    print("=" * 60 + "\n")
    
    uvicorn.run(app, host="0.0.0.0", port=8879)

